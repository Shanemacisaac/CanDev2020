{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from dateutil import parser\n",
    "from datetime import datetime\n",
    "from crontab import CronTab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrapes Nova Scotia data\n",
    "def web_scrape_NS(soup):\n",
    "    data = []\n",
    "    table = soup.find_all('td', attrs={'width': '45%'})\n",
    "    table = [ele.text.strip() for ele in table] # strip tags\n",
    "    data.append([ele for ele in table if ele]) # strip empty values\n",
    "    data = data[0]\n",
    "\n",
    "    load = findValue('Net Load', data)\n",
    "    return load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrapes New Brunswick data\n",
    "def web_scrape_NB(soup):\n",
    "    load_box = soup.find('td', attrs={'id': 'nb-load'})\n",
    "    load = load_box.text.strip() # strip() is used to remove starting and trailing\n",
    "    return load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrapes Ontario data\n",
    "def web_scrape_ON(soup):\n",
    "    span = soup.findAll(string=re.compile(\"MW\")) #'div', class_=\"col-sm-3\")\n",
    "    for i in range(len(span)):\n",
    "        span[i] = span[i][:len(span[i])-3]\n",
    "    load = span[1]\n",
    "    types = ['0', span[15], span[13], span[17], span[14], span[16], span[12]]\n",
    "    return load, types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrapes Newfoundland and Labrador data\n",
    "def web_scrape_NF(soup):\n",
    "    loadStr = soup.find_all(string=re.compile(\"MW\"))[0]\n",
    "    load = loadStr[:len(loadStr)-4]\n",
    "    return load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrapes Alberta data\n",
    "def web_scrape_AB(soup):\n",
    "    link = soup.find(string = re.compile(\"Alberta Total Net Generation\"))\n",
    "    load = link.find_next(string = True)\n",
    "    srcs = [\"COAL\", \"GAS\", \"HYDRO\", \"OTHER\", \"WIND\"]\n",
    "    sources = []\n",
    "    for i in range(len(srcs)):\n",
    "        sources.append(soup.find(string = re.compile(srcs[i])).find_next(string = True).find_next(string = True))\n",
    "    sources.append('0')\n",
    "    sources.append('0')\n",
    "    return load, sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findValue(element, data):\n",
    "    i = 0\n",
    "    for ele in data:\n",
    "        if ele == element:\n",
    "            loadIndex = i\n",
    "        else:\n",
    "            i += 1\n",
    "    load = data[loadIndex+1]\n",
    "    return load\n",
    "\n",
    "# returns the BeautifulSoup given a url to scrape\n",
    "def urlOpen(url):\n",
    "    html = urllib.request.urlopen(url)\n",
    "    return BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '334', '4785', '8', '3706', '0', '10836']\n",
      "['3204', '6260', '158', '257', '149', '0', '0']\n",
      "['Coal', 'Gas', 'Hydro', 'Biomass', 'Wind', 'Solar', 'Nuclear']\n"
     ]
    }
   ],
   "source": [
    "urls = {\"NF\": \"https://nlhydro.com/system-information/supply-and-demand/\", \n",
    "        \"ON\": \"http://www.ieso.ca/en/Power-Data/This-Hours-Data\", \n",
    "        \"NB\": \"https://tso.nbpower.com/Public/en/SystemInformation_realtime.asp\",\n",
    "        \"NS\": \"https://resourcesprd-nspower.aws.silvertech.net/oasis/current_report.shtml\",\n",
    "        \"AB\": \"http://ets.aeso.ca/ets_web/ip/Market/Reports/CSDReportServlet\"}\n",
    "soupNF = urlOpen(urls[\"NF\"])\n",
    "soupON = urlOpen(urls[\"ON\"])\n",
    "soupNB = urlOpen(urls[\"NB\"])\n",
    "soupNS = urlOpen(urls[\"NS\"])\n",
    "soupAB = urlOpen(urls[\"AB\"])\n",
    "time = str(datetime.now().hour) + \":\" + str(datetime.now().minute)\n",
    "\n",
    "loadNF = web_scrape_NF(soupNF)\n",
    "loadON, sourcesON = web_scrape_ON(soupON)\n",
    "loadNB = web_scrape_NB(soupNB)\n",
    "loadNS = web_scrape_NS(soupNS)\n",
    "loadAB, sourcesAB = web_scrape_AB(soupAB)\n",
    "loadList = [loadNF, loadON, loadNB, loadNS, loadAB]\n",
    "# strip any commas from the load values\n",
    "for i in range(len(loadList)):\n",
    "    loadList[i] = loadList[i].replace(',', '')\n",
    "for i in range(len(sourcesON)):\n",
    "    sourcesON[i] = sourcesON[i].replace(',', '')\n",
    "for i in range(len(sourcesAB)):\n",
    "    sourcesAB[i] = sourcesAB[i].replace(',', '') \n",
    "    \n",
    "print(sourcesON)\n",
    "print(sourcesAB)\n",
    "\n",
    "sourcesType = [\"Coal\", \"Gas\", \"Hydro\", \"Biomass\", \"Wind\", \"Solar\", \"Nuclear\"]\n",
    "print(sourcesType)\n",
    "dfSources = pd.DataFrame(columns=['Time', 'Source (MW)', 'Type', 'Province'])\n",
    "for i in range(len(sourcesON)):\n",
    "    dfSources = dfSources.append({'Time': time, 'Source (MW)': sourcesON[i], 'Type': sourcesType[i], 'Province': 'Ontario'}, ignore_index = True)\n",
    "    dfSources = dfSources.append({'Time': time, 'Source (MW)': sourcesAB[i], 'Type': sourcesType[i], 'Province': 'Alberta'}, ignore_index = True)\n",
    "dfSources.to_csv('EnergySources.csv', index = False, encoding='cp1252')\n",
    "    \n",
    "provinces = [\"Newfoundland and Labrador\", \"Ontario\", \"New Brunswick\", \"Nova Scotia\", \"Alberta\"]\n",
    "dfLoad = pd.DataFrame(columns=['Time','Net Load (MW)', 'Province'])\n",
    "for i in range(len(timeList)):\n",
    "    dfLoad = dfLoad.append({'Time': time, 'Net Load (MW)': loadList[i], 'Province': provinces[i]}, ignore_index = True)\n",
    "dfLoad.to_csv('Energy.csv', index = False, encoding='cp1252')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
